{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "code_folding": [
     88,
     102,
     126,
     145,
     153,
     156,
     184,
     195
    ],
    "jupyter": {
     "outputs_hidden": true
    },
    "pycharm": {
     "is_executing": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os.path\n",
    "from googleapiclient.discovery import build\n",
    "from google_auth_oauthlib.flow import InstalledAppFlow\n",
    "from google.auth.transport.requests import Request\n",
    "from selectolax.parser import HTMLParser\n",
    "import mailparser\n",
    "import pickle\n",
    "import base64\n",
    "import email\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import traceback\n",
    "import qgrid\n",
    "\n",
    "\n",
    "class WalnutDataSaver():\n",
    "    filter_query=\"from:report-no-reply@getwalnut.in\"\n",
    "    walnut_payment_keywords_to_source ={\"hdfc\":\"hdfc\",\n",
    "                                    \"icici\":\"icici\",\n",
    "                                    \"kotak\":\"kotak\",\n",
    "                                        \"paytm\":\"paytm\",\n",
    "                                        \"amex\":\"amex\"}\n",
    "    @staticmethod\n",
    "    def clean_walnut_csv_and_save_df(mail_utils_class, datastore_path, sheet_id):\n",
    "        if not WalnutDataSaver.save_walnut_attachment(mail_utils_class, datastore_path):\n",
    "            print(\"no walnut attachment\")\n",
    "            return\n",
    "        with open(datastore_path+'/walnut_expenses.csv','rb') as f:\n",
    "            walnut_df=pd.read_csv(f)\n",
    "\n",
    "        # Changing column names\n",
    "        walnut_df.columns=walnut_df[4:5].values.tolist()[0]\n",
    "        \n",
    "        #Removing useless rows\n",
    "        walnut_df=walnut_df[5:-1]\n",
    "        \n",
    "        walnut_df=walnut_df.rename(columns={\"TIME\":\"time\",\"AMOUNT\":\"amount\"})\n",
    "        walnut_df['from']=walnut_df['ACCOUNT']\n",
    "        walnut_df['time']=walnut_df['DATE']+\" \"+walnut_df['time']\n",
    "        walnut_df['time'] = pd.to_datetime(walnut_df['time'], format=\"%d-%m-%y %I:%M %p\")\n",
    "\n",
    "        walnut_df['time']=walnut_df.time.map(lambda x: x.replace(second=0,microsecond=0))\n",
    "        walnut_df['amount']=walnut_df.amount.map(lambda x: x.replace(\",\",\"\"))\n",
    "        walnut_df['amount'] = walnut_df['amount'].astype('float') \n",
    "\n",
    "        # Replace all elements of from column from which contains keys of walnut_pay.. dict with corresponding values\n",
    "        # this causes hdfc credit card to be replaced with hdfc, but does not cause an issue right now\n",
    "        # because we later pickup only transactions which we have record of from mail\n",
    "        for key,value in WalnutDataSaver.walnut_payment_keywords_to_source.items():\n",
    "            walnut_df.loc[walnut_df['from'].str.contains(key,case=False), 'from'] = value\n",
    "        walnut_df.to_pickle(datastore_path+'/walnut_processed.pickle')\n",
    "        walnut_df['time']=walnut_df.time.map(lambda x: x.timestamp())\n",
    "        walnut_df=walnut_df.fillna(\"\")\n",
    "        mail_utils_class.write_data_to_google_sheet(sheet_id,\"walnut\",walnut_df.T.reset_index().T.values.tolist())\n",
    "        \n",
    "        \n",
    "    @staticmethod\n",
    "    def save_walnut_attachment(mail_utils_class, datastore_path):\n",
    "        walnut_msg_ids=mail_utils_class.get_all_message_ids(WalnutDataSaver.filter_query)\n",
    "        # Assuming that gmail always serves messages by reverse time sorting, so that we get latest walnut email\n",
    "        # available\n",
    "        try:\n",
    "            walnut_msg_id = walnut_msg_ids[0]['id']\n",
    "        except IndexError:\n",
    "            return False\n",
    "        message=mail_utils_class.fetch_mail_from_id(walnut_msg_id,raw_format=False)\n",
    "        found_csv=False\n",
    "        for part in message['payload']['parts']:\n",
    "            if part['filename'] and \".csv\" in part['filename']:\n",
    "                attachment_id = part['body']['attachmentId']\n",
    "                attachment= mail_utils_class.gmail_service.users().messages().attachments().get(userId='me',\n",
    "                                                                                 messageId=walnut_msg_id,\n",
    "                                                                                 id=attachment_id).execute()\n",
    "                file_data = base64.urlsafe_b64decode(attachment['data'].encode('UTF-8'))\n",
    "                path = '/'.join([datastore_path, 'walnut_expenses.csv'])\n",
    "                f = open(path, 'wb')\n",
    "                f.write(file_data)\n",
    "                f.close()\n",
    "                found_csv=True\n",
    "                break\n",
    "        if not found_csv:\n",
    "            print(\"No attachment was found in latest walnut mail.\")\n",
    "            return False\n",
    "        else:\n",
    "            return True\n",
    "                \n",
    "# If modifying these scopes, delete the file token.pickle.\n",
    "class MailUtils():\n",
    "    SCOPES = ['https://www.googleapis.com/auth/gmail.readonly','https://www.googleapis.com/auth/spreadsheets']\n",
    "    def __init__(self, datastore_path):        \n",
    "        if not os.path.exists(datastore_path):\n",
    "            print(f\"Creating Directory {datastore_path}\")\n",
    "            os.mkdir(datastore_path)\n",
    "        self.token_path = datastore_path+\"/token.pickle\"\n",
    "        self.client_secrets_path = datastore_path+\"/credentials.json\" #'/Users/sanchitsharma/Documents/spentAnalysis/credentials.json'\n",
    "        self.gmail_service = self.get_google_service(service_name='gmail') \n",
    "    \n",
    "    @classmethod\n",
    "    def get_text_from_mail_body(cls,html):\n",
    "        tree = HTMLParser(html)\n",
    "\n",
    "        if tree.body is None:\n",
    "            return None\n",
    "\n",
    "        for tag in tree.css('script'):\n",
    "            tag.decompose()\n",
    "        for tag in tree.css('style'):\n",
    "            tag.decompose()\n",
    "\n",
    "        text = tree.body.text(separator='\\n')\n",
    "        return text\n",
    "    \n",
    "    def get_google_service(self, service_name=\"gmail\", version='v1'): \n",
    "        # The file token.pickle stores the user's access and refresh tokens, and is\n",
    "        # created automatically when the authorization flow completes for the first\n",
    "        # time.\n",
    "        creds = None        \n",
    "        if os.path.exists(self.token_path):\n",
    "            with open(self.token_path, 'rb') as token:\n",
    "                creds = pickle.load(token)\n",
    "                \n",
    "        # If there are no (valid) credentials available, let the user log in.\n",
    "        if not creds or not creds.valid:\n",
    "            if creds and creds.expired and creds.refresh_token:\n",
    "                creds.refresh(Request())\n",
    "            else:\n",
    "                try:\n",
    "                    flow = InstalledAppFlow.from_client_secrets_file(self.client_secrets_path, MailUtils.SCOPES)\n",
    "                    creds = flow.run_local_server(port=0)\n",
    "                except FileNotFoundError:\n",
    "                    raise ValueError(f\"Download credentials file in {datastore_path} folder by enabling the GMAIL API for your account at - https://developers.google.com/gmail/api/quickstart/python\")\n",
    "            # Save the credentials for the next run\n",
    "            with open(self.token_path, 'wb') as token:\n",
    "                pickle.dump(creds, token)\n",
    "        return build(service_name, version, credentials=creds)\n",
    "    \n",
    "    def get_all_message_ids(self,filter_query):\n",
    "    \n",
    "        #some_days_ago_date_str=(datetime.datetime.now() - datetime.timedelta(days=5)).strftime(\"%d-%m-%Y\")\n",
    "\n",
    "        #query=f'{filter_query},after:{some_days_ago_date_str}'\n",
    "\n",
    "        tomorrow_date_str = (datetime.datetime.now() + datetime.timedelta(days=1)).strftime(\"%m-%d-%Y\")\n",
    "        query = f'{filter_query},before:{tomorrow_date_str}'\n",
    "        print(query)\n",
    "        response = self.gmail_service.users().messages().list(userId='me', q=query).execute()\n",
    "        message_ids = response.get('messages', [])\n",
    "\n",
    "        while 'nextPageToken' in response:\n",
    "            page_token = response['nextPageToken']\n",
    "            response = self.gmail_service.users().messages().list(userId='me', q=query,\n",
    "                                                       pageToken=page_token).execute()\n",
    "            message_ids.extend(response['messages'])\n",
    "        return message_ids\n",
    "    \n",
    "    def fetch_mail_from_id(self,msg_id,raw_format=True):\n",
    "        \"\"\"    \n",
    "        :param gmail_service: \n",
    "        :param id: gmail id of the mail \n",
    "        :return: mail object\n",
    "        \"\"\"\n",
    "        if raw_format:            \n",
    "            return self.gmail_service.users().messages().get(userId='me', id=msg_id, format='raw').execute()\n",
    "        else:\n",
    "            return self.gmail_service.users().messages().get(userId='me', id=msg_id).execute()\n",
    "    \n",
    "    def fetch_mail_details(self,message_id):\n",
    "        message = self.fetch_mail_from_id(message_id)         \n",
    "        try:\n",
    "            msg_str = base64.urlsafe_b64decode(message['raw'].encode('ASCII')).decode('utf-8')\n",
    "            mail_body = mailparser.parse_from_string(msg_str).body\n",
    "            text_body = MailUtils.get_text_from_mail_body(mail_body)\n",
    "            mail_details = {\"mail_text\":text_body.split(),'timestamp':int(message['internalDate'])/1000}\n",
    "            return mail_details\n",
    "        except UnicodeDecodeError:\n",
    "            print(f\"Error message on f{datetime.datetime.fromtimestamp(int(message['internalDate'])/1000)} for message_id f{message_id}\")\n",
    "    \n",
    "    def read_data_from_google_sheet(self, sheet_id, subsheet_name):\n",
    "        sheet_service = self.get_google_service(service_name=\"sheets\",version='v4')\n",
    "        result_input = sheet_service.spreadsheets().values().get(spreadsheetId=sheet_id,\n",
    "                                    range=subsheet_name+\"!A1:AA10000\").execute()\n",
    "        values_input = result_input.get('values', [])                  \n",
    "        return values_input\n",
    "                  \n",
    "    def write_data_to_google_sheet(self, sheet_id, subsheet_name, rows_to_be_written):\n",
    "        sheet_service = self.get_google_service(service_name=\"sheets\",version='v4')\n",
    "        creat_sheet_body = {\"requests\": [\n",
    "                                    {\"addSheet\": {\n",
    "                                            \"properties\": {\"title\": subsheet_name}\n",
    "                                      }}            \n",
    "                                      ]}\n",
    "        try:\n",
    "            sheet_service.spreadsheets().batchUpdate(body=creat_sheet_body,\n",
    "                                            spreadsheetId=sheet_id).execute()\n",
    "        except:\n",
    "            pass\n",
    "        sheet_service.spreadsheets().values().update(\n",
    "        spreadsheetId=sheet_id,\n",
    "        valueInputOption='RAW',\n",
    "        range=subsheet_name+\"!A1:AA10000\",\n",
    "        body=dict(\n",
    "            majorDimension='ROWS',\n",
    "            values=rows_to_be_written)\n",
    "        ).execute()\n",
    "        \n",
    "class TransactionMailManager():\n",
    "                  \n",
    "    payment_source_to_filter_dict = {'paytm':\"from:no-reply@paytm.com\",\n",
    "                                     \"kotak\":\"from:bankalerts@kotak.com\",\n",
    "                                     \"hdfc\":\"from:alerts@hdfcbank.net\",\n",
    "                                     \"amex\":\"americanexpress@welcome.aexp.com\",\n",
    "                                     \"phonepe\":\"noreply@phonepe.com\",\n",
    "                                     \"mobikwik\":\"no-reply@mobikwik.com\",\n",
    "                                    \"walnut\":\"placeholder\"}\n",
    "\n",
    "                  \n",
    "    def __init__(self, username, payment_source_name=None, write_to_sheet_id=None):\n",
    "        self.username=username\n",
    "        self.payment_source_name = payment_source_name\n",
    "        self.write_to_sheet_id = write_to_sheet_id\n",
    "        self.datastore_path = username+\"_datastore\"\n",
    "        self.filter_query = self.__class__.payment_source_to_filter_dict[payment_source_name]\n",
    "        self.messages_store_path = self.datastore_path +\"/\"+ payment_source_name+\".pickle\"\n",
    "        self.mail_utils = MailUtils(self.datastore_path)\n",
    "    \n",
    "    \n",
    "    def get_old_messages_dict_from_sheet(self):    \n",
    "        list_values = self.mail_utils.read_data_from_google_sheet(self.write_to_sheet_id,self.payment_source_name)        \n",
    "        return {row[0]:{'mail_text':row[1].split(),'timestamp':int(row[2])} for row in list_values}\n",
    "                  \n",
    "    def get_old_messages_dict(self):                  \n",
    "        try:\n",
    "            with open(self.messages_store_path,'rb') as fl:\n",
    "                old_messages = pickle.load(fl)\n",
    "            print(f\"Got  {len(old_messages)} old messages.\")\n",
    "        except IOError as e:\n",
    "            print(f\"Got IOError - {e}\")\n",
    "            old_messages = {} \n",
    "                  \n",
    "        return old_messages\n",
    "    \n",
    "    def mail_fetcher(self):  \n",
    "        \"\"\"\n",
    "        This will store all mails from this filter_query in a file of the same name.\n",
    "        Mails will be pickled in following format \n",
    "        {<mail_id>:{'mail_text':<mail text (each word separated by *;*)>, 'datetime':<sent time of mail>)\n",
    "        If a file with same name exists, it will only fetch those messages which are not already contained in the file.  \n",
    "        :param filter_query: filter to pass gmail api to search mails \n",
    "        :param to_store_name: name to store the file with \n",
    "        :return: None\n",
    "        \"\"\"\n",
    "        old_messages = self.get_old_messages_dict()\n",
    "        old_messages_from_sheet = self.get_old_messages_dict_from_sheet()\n",
    "#         correct=True\n",
    "        for key,value in old_messages_from_sheet.items():\n",
    "            if not value==old_messages[key]:\n",
    "                print(\"Problem\",value,\"\\nProblem\",old_messages[key])\n",
    "                break\n",
    "        message_ids = self.mail_utils.get_all_message_ids(self.filter_query)\n",
    "        new_messages_dict = {}\n",
    "        msg_ids_not_in_file=[msg_id_dict for msg_id_dict in message_ids if msg_id_dict['id'] not in old_messages]\n",
    "\n",
    "        for i, msg_id_dict in enumerate(msg_ids_not_in_file):\n",
    "            msg_id = msg_id_dict['id']\n",
    "#             print(\"getting msg for\",msg_id)\n",
    "            new_messages_dict[msg_id] = self.mail_utils.fetch_mail_details(msg_id)\n",
    "\n",
    "        old_messages.update(new_messages_dict)\n",
    "        print(f\"Final number of messages {len(old_messages)}.\\n-----------------\\n\")\n",
    "            \n",
    "        with open(self.messages_store_path,'wb') as fl:  \n",
    "            pickle.dump(old_messages,fl,protocol=pickle.HIGHEST_PROTOCOL)\n",
    "#         print(list(old_messages.items())[0])\n",
    "        if self.write_to_sheet_id:\n",
    "            list_to_be_written = [[key,\" \".join(dic['mail_text']),dic['timestamp']] for key,dic in old_messages.items() if dic is not None]\n",
    "            list_to_be_written.sort(key=lambda row:row[2])                  \n",
    "            self.mail_utils.write_data_to_google_sheet(self.write_to_sheet_id,self.payment_source_name,\n",
    "                                                       list_to_be_written)\n",
    "        \n",
    "                  \n",
    "    def execute(self):                  \n",
    "        if self.payment_source_name=='walnut':\n",
    "            WalnutDataSaver.clean_walnut_csv_and_save_df(self.mail_utils, self.datastore_path, self.write_to_sheet_id)\n",
    "        else:\n",
    "            \n",
    "            self.mail_fetcher()\n",
    "\n",
    "def store_transactions_messages_in_datastore(username,payment_sources,write_to_sheet_id):\n",
    "    for payment_source_name in payment_sources:\n",
    "        tmm=TransactionMailManager(username,payment_source_name=payment_source_name,write_to_sheet_id=write_to_sheet_id)\n",
    "        tmm.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got  247 old messages.\n",
      "from:bankalerts@kotak.com,before:05-05-2020\n",
      "Final number of messages 247.\n",
      "-----------------\n",
      "\n",
      "Got  151 old messages.\n",
      "from:alerts@hdfcbank.net,before:05-05-2020\n",
      "Final number of messages 151.\n",
      "-----------------\n",
      "\n",
      "Got  1212 old messages.\n",
      "from:no-reply@paytm.com,before:05-05-2020\n",
      "Final number of messages 1212.\n",
      "-----------------\n",
      "\n",
      "from:report-no-reply@getwalnut.in,before:05-05-2020\n"
     ]
    }
   ],
   "source": [
    "#####Sulinder\n",
    "# username=\"sulinder\"\n",
    "# payment_sources=[\"kotak\",\"paytm\",\"phonepe\",\"mobikwik\"]\n",
    "# sheet_id=\"1Hyk2Ex7xN96lisiNnNtRxQ5nQeMcabml1Rdza2Cjoc8\"\n",
    "#####Sanchit\n",
    "username=\"sanchit\"\n",
    "payment_sources=[\"kotak\",\"hdfc\",\"paytm\",\"walnut\"]\n",
    "# payment_sources=[\"walnut\"]\n",
    "sheet_id=\"1gQoZfriTs7pXRJFEdbyCOe0-NsPzIwKbCenVEZVrphA\"\n",
    "######\n",
    "store_transactions_messages_in_datastore(username,payment_sources,sheet_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "376656626c1f4780bfa9a190364d0612",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "QgridWidget(grid_options={'fullWidthRows': True, 'syncColumnCellResize': True, 'forceFitColumns': True, 'defauâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "qgrid.show_grid(pd.read_pickle(\"sanchit_datastore/walnut_processed.pickle\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 3, 4, 5]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s=[3,4,5,1]\n",
    "s.sort()\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     0\n",
       "0  1.0\n",
       "1  2.0\n",
       "2  3.0\n",
       "3  NaN"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([1,2,3,None])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\"a\":{2:\"a\",1:\"e32e3\"}}=={\"a\":{2:\"a\",1:\"e32e3\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "metadata": {
     "collapsed": false
    },
    "source": []
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
